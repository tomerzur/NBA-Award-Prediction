{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Linear Regression<h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import rbo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, I will be using a linear regression to make predictions for each award. This notebook includes the code I used to create the linear regression and make predictions for each award.\n",
    "<br><br>\n",
    "This code should be run after you have finished running the 'preprocessing' notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Helper Functions</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I am loading helper functions that I wrote in order to load my data, scale the data, fill in missing/NA values, and calculate and print my accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "GET_TEST_RESULTS = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve data for the specified award\n",
    "def get_data(award_name):\n",
    "    x_train_pnames = pd.read_csv(f'data/train_x_{award}.csv', index_col=0)\n",
    "    y_train = pd.read_csv(f'data/train_y_{award}.csv', index_col=0)\n",
    "    x_dev_pnames = pd.read_csv(f'data/dev_x_{award}.csv', index_col=0)\n",
    "    y_dev = pd.read_csv(f'data/dev_y_{award}.csv', index_col=0)\n",
    "    x_test_pnames = pd.read_csv(f'data/test_x_{award}.csv', index_col=0)\n",
    "    y_test = pd.read_csv(f'data/test_y_{award}.csv', index_col=0)\n",
    "    x_train = x_train_pnames.drop(columns=['player', 'season'])\n",
    "    x_dev = x_dev_pnames.drop(columns=['player', 'season'])\n",
    "    x_test = x_test_pnames.drop(columns=['player', 'season'])\n",
    "    return x_train_pnames, x_train, y_train, x_dev_pnames, x_dev, y_dev, x_test_pnames, x_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some missing statistics in my dataset. These occur mostly for older players, as there are some statistics (such as steals and blocks) that weren't kept track of when the NBA first started. I will deal with these missing statistics in three ways:\n",
    "Method 2 - Fill in zeros for all of the missing stats, and use all the data\n",
    "Method 5 - Fill in mean values for all of missing stats, and use all of the data\n",
    "Method 4 - Use linear regressions to predict each of the missing stats, and use all of the data\n",
    "\n",
    "Some other ways I may implement in the future to explore dealing with missing statistics are:\n",
    "Remove all of these rows (This should end up using all player seasons after 1979)\n",
    "Drop all the columns with missing stats, and use all of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in the missing statistics (that were not kept track of for older players)\n",
    "# using one of the three methods mentioned above\n",
    "def fill_missing_stats(x_train, x_train_pnames, x_dev, x_dev_pnames, x_test, x_test_pnames, method=4):\n",
    "    if method == 2:\n",
    "        x_train_filled = x_train.fillna(0)\n",
    "        x_dev_filled = x_dev.fillna(0)\n",
    "        x_test_filled = x_test.fillna(0)\n",
    "    elif method == 4:\n",
    "        x_train_filled = copy.copy(x_train_pnames)\n",
    "        x_dev_filled = copy.copy(x_dev_pnames)\n",
    "        x_test_filled = copy.copy(x_test_pnames)\n",
    "        # three_p and three_pa - if season < 1980, set to NA\n",
    "        x_train_filled['three_p'] = np.where(x_train_filled.season < 1980, float('NaN'), x_train_filled.three_p)\n",
    "        x_train_filled['three_pa'] = np.where(x_train_filled.season < 1980, float('NaN'), x_train_filled.three_pa)\n",
    "        \n",
    "        x_train_filled = x_train_filled.drop(columns=['player', 'season'])\n",
    "        x_dev_filled = x_dev_filled.drop(columns=['player', 'season'])\n",
    "        x_test_filled = x_test_filled.drop(columns=['player', 'season'])\n",
    "\n",
    "        # predict all missing values for these stats using lin reg\n",
    "        # train data: player seasons where stat != NaN\n",
    "        # test data: player seasons where stat == NaN\n",
    "        for stat in ['three_p', 'three_pa', 'gs', 'orb', 'drb', 'stl', 'blk', 'tov']:\n",
    "            # check if this stat has missing values\n",
    "            if x_train_filled[stat].isnull().values.any():\n",
    "                train_stat = x_train_filled[x_train_filled[stat].notna()]\n",
    "                # for all lin reg predictions, don't use any of the columns that have missing values\n",
    "                x_train_stat = train_stat.drop(columns=['three_p', 'three_pa', 'gs', 'orb', 'drb', 'stl', 'blk', 'tov', 'three_pct', 'gs_pct'])\n",
    "                y_train_stat = train_stat[[stat]]\n",
    "                test_stat = x_train_filled[~x_train_filled[stat].notna()]\n",
    "                x_test_stat = test_stat.drop(columns=['three_p', 'three_pa', 'gs', 'orb', 'drb', 'stl', 'blk', 'tov', 'three_pct', 'gs_pct'])\n",
    "\n",
    "                reg_stat = LinearRegression().fit(x_train_stat, y_train_stat)\n",
    "                pred_test_stat = reg_stat.predict(x_test_stat)\n",
    "                pred_stat_dict = {index: round(value[0], 3) for index, value in zip(x_train_filled[~x_train_filled[stat].notna()].index, pred_test_stat)}\n",
    "                x_train_filled[stat] = x_train_filled[stat].fillna(pred_stat_dict)\n",
    "\n",
    "        # fill in three_pct - three_p / three_pa, gs_pct - gs / g\n",
    "        x_train_filled['three_pct'] = x_train_filled['three_p'] / x_train_filled['three_pa']\n",
    "        x_train_filled['gs_pct'] = x_train_filled['gs'] / x_train_filled['g']\n",
    "        x_train_filled = x_train_filled.fillna(0)\n",
    "        x_dev_filled['three_pct'] = x_dev_filled['three_p'] / x_dev_filled['three_pa']\n",
    "        x_dev_filled = x_dev_filled.fillna(0)\n",
    "        x_test_filled['three_pct'] = x_test_filled['three_p'] / x_test_filled['three_pa']\n",
    "        x_test_filled = x_test_filled.fillna(0)\n",
    "    elif method == 5:\n",
    "        x_train_filled = x_train.fillna(x_train.mean())\n",
    "        x_dev_filled = x_dev.fillna(x_dev.mean())\n",
    "        x_test_filled = x_test.fillna(x_test.mean())\n",
    "    else:\n",
    "        print('method of dealing with missing stats must be either 2, 4, or 5')\n",
    "    return x_train_filled, x_dev_filled, x_test_filled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I decided to measure my models' performance using three metrics: Mean Squared Error, % of correct MVP predictions, and Rank-Biased Overlap.\n",
    "I chose to use rank-biased overlap because it is an accuracy metric for rankings that weights higher ranked items more than lower ranked items. In addition, when comparing two lists using this metric, rank-biased overlap can deal with items that occur in one list but are not seen in the other list.\n",
    "For more information on rank-biased overlap, see this article: http://codalism.com/research/papers/wmz10_tois.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print accuracy metrics by comparing the given lists (y_pred and y_actual)\n",
    "# accuracy metrics that I am using are % of correct winners picked, rank biased overlap, and mean squared error\n",
    "def print_accuracy(y_pred, y_actual, x_pnames, rbo_cutoff = None, verbose=0):\n",
    "    all_data = copy.copy(x_pnames)\n",
    "    all_data['award_pts_actual'] = y_actual['award_pts_won']\n",
    "    all_data['award_pts_pred'] = y_pred\n",
    "    num_correct = 0\n",
    "    num_yrs = 0\n",
    "    rbo_vals = []\n",
    "    for year in set(all_data.season):\n",
    "        # a. % of correct winners picked\n",
    "        data_in_yr = all_data[all_data['season'] == year]\n",
    "        pred_winner_row = data_in_yr['award_pts_pred'].argmax()\n",
    "        actual_winner_row = data_in_yr['award_pts_actual'].argmax()\n",
    "        pred_winner, pred_pts = data_in_yr.iloc[pred_winner_row]['player'], data_in_yr.iloc[pred_winner_row]['award_pts_pred']\n",
    "        actual_winner, actual_pts = data_in_yr.iloc[actual_winner_row]['player'], data_in_yr.iloc[actual_winner_row]['award_pts_actual']\n",
    "        if verbose > 0:\n",
    "            print(f'{year}')\n",
    "            print(f'Predicted Winner: {pred_winner} ({pred_pts} award pts)')\n",
    "            print(f'Actual Winner: {actual_winner} ({actual_pts} award pts)')\n",
    "        if pred_winner == actual_winner:\n",
    "            num_correct += 1\n",
    "        num_yrs += 1\n",
    "        \n",
    "        # b. Rank-Biased Overlap\n",
    "        # calculate RBO:\n",
    "        # get rows in given year with players that received votes - sorted by num votes\n",
    "        vote_getters_df = data_in_yr[data_in_yr['award_pts_actual'] > 0]\n",
    "        num_vote_getters = len(vote_getters_df)\n",
    "        vote_getters_df = vote_getters_df.sort_values(by=['award_pts_actual'], ascending=False)\n",
    "        # get top-(num_vote_getters) rows from predictions\n",
    "        pred_vote_getters_df = data_in_yr.sort_values(by=['award_pts_pred'], ascending=False)\n",
    "        if rbo_cutoff == None:\n",
    "            pred_vote_getters_df = pred_vote_getters_df[:num_vote_getters]\n",
    "        else:\n",
    "            cutoff = min(rbo_cutoff, num_vote_getters)\n",
    "            vote_getters_df = vote_getters_df[:cutoff]\n",
    "            pred_vote_getters_df = pred_vote_getters_df[:cutoff]\n",
    "        vote_getters = vote_getters_df['player'].values\n",
    "        pred_vote_getters = pred_vote_getters_df['player'].values\n",
    "        # deal with edge case where two vote getters have exact same name\n",
    "        vote_getters = list(set(vote_getters))\n",
    "        pred_vote_getters = list(set(pred_vote_getters))\n",
    "        #print(len(vote_getters))\n",
    "        #print(len(pred_vote_getters))\n",
    "        if verbose > 1:\n",
    "            print('Actual vote getters:')\n",
    "            print(vote_getters)\n",
    "            print(f'Predicted top-{num_vote_getters} vote getters:')\n",
    "            print(pred_vote_getters)\n",
    "        # compute RBO from these two lists\n",
    "        rbo_num = rbo.RankingSimilarity(vote_getters, pred_vote_getters).rbo()\n",
    "        rbo_vals.append(rbo_num)\n",
    "        if verbose > 0:\n",
    "            print(f'Rank Biased Overlap: {rbo_num}')\n",
    "        \n",
    "    print(f'% of winners predicted correctly: {round(num_correct / num_yrs * 100, 2)}%')\n",
    "    print(f'Average Rank-Biased Overlap: {round(sum(rbo_vals) / len(rbo_vals), 3)}')\n",
    "    # c. MSE\n",
    "    mse = mean_squared_error(y_actual, y_pred)\n",
    "    print(f'Mean Squared Error for Linear Regression: {mse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Implementing Linear Regression</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, I implement a separate linear regression for predicting each of the five awards. I also print out the accuracy of each linear regression using the three accuracy metrics mentioned above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "*****mvp*****\n",
      "\n",
      "filling na values using method 4\n",
      "\n",
      "Train accuracy:\n",
      "% of winners predicted correctly: 43.64%\n",
      "Average Rank-Biased Overlap: 0.568\n",
      "Mean Squared Error for Linear Regression: 2530.6445213701336\n",
      "\n",
      "Dev accuracy:\n",
      "% of winners predicted correctly: 60.0%\n",
      "Average Rank-Biased Overlap: 0.698\n",
      "Mean Squared Error for Linear Regression: 4041.8058795340175\n",
      "\n",
      "filling na values using method 2\n",
      "\n",
      "Train accuracy:\n",
      "% of winners predicted correctly: 43.64%\n",
      "Average Rank-Biased Overlap: 0.574\n",
      "Mean Squared Error for Linear Regression: 2541.3643425513865\n",
      "\n",
      "Dev accuracy:\n",
      "% of winners predicted correctly: 40.0%\n",
      "Average Rank-Biased Overlap: 0.673\n",
      "Mean Squared Error for Linear Regression: 4001.1947572209865\n",
      "\n",
      "filling na values using method 5\n",
      "\n",
      "Train accuracy:\n",
      "% of winners predicted correctly: 41.82%\n",
      "Average Rank-Biased Overlap: 0.583\n",
      "Mean Squared Error for Linear Regression: 2534.300604737239\n",
      "\n",
      "Dev accuracy:\n",
      "% of winners predicted correctly: 60.0%\n",
      "Average Rank-Biased Overlap: 0.693\n",
      "Mean Squared Error for Linear Regression: 4010.8966288581823\n",
      "\n",
      "\n",
      "*****dpoy*****\n",
      "\n",
      "filling na values using method 4\n",
      "\n",
      "Train accuracy:\n",
      "% of winners predicted correctly: 28.57%\n",
      "Average Rank-Biased Overlap: 0.342\n",
      "Mean Squared Error for Linear Regression: 204.7148158312748\n",
      "\n",
      "Dev accuracy:\n",
      "% of winners predicted correctly: 20.0%\n",
      "Average Rank-Biased Overlap: 0.36\n",
      "Mean Squared Error for Linear Regression: 523.1768281454953\n",
      "\n",
      "filling na values using method 2\n",
      "\n",
      "Train accuracy:\n",
      "% of winners predicted correctly: 28.57%\n",
      "Average Rank-Biased Overlap: 0.342\n",
      "Mean Squared Error for Linear Regression: 204.71481547322094\n",
      "\n",
      "Dev accuracy:\n",
      "% of winners predicted correctly: 20.0%\n",
      "Average Rank-Biased Overlap: 0.36\n",
      "Mean Squared Error for Linear Regression: 523.1768566474012\n",
      "\n",
      "filling na values using method 5\n",
      "\n",
      "Train accuracy:\n",
      "% of winners predicted correctly: 28.57%\n",
      "Average Rank-Biased Overlap: 0.347\n",
      "Mean Squared Error for Linear Regression: 204.6933151380242\n",
      "\n",
      "Dev accuracy:\n",
      "% of winners predicted correctly: 20.0%\n",
      "Average Rank-Biased Overlap: 0.345\n",
      "Mean Squared Error for Linear Regression: 523.199263213497\n",
      "\n",
      "\n",
      "*****roy*****\n",
      "\n",
      "filling na values using method 4\n",
      "\n",
      "Train accuracy:\n",
      "% of winners predicted correctly: 65.96%\n",
      "Average Rank-Biased Overlap: 0.541\n",
      "Mean Squared Error for Linear Regression: 1050.8713637655542\n",
      "\n",
      "Dev accuracy:\n",
      "% of winners predicted correctly: 40.0%\n",
      "Average Rank-Biased Overlap: 0.586\n",
      "Mean Squared Error for Linear Regression: 4517.666729629855\n",
      "\n",
      "filling na values using method 2\n",
      "\n",
      "Train accuracy:\n",
      "% of winners predicted correctly: 65.96%\n",
      "Average Rank-Biased Overlap: 0.543\n",
      "Mean Squared Error for Linear Regression: 1029.9108156377913\n",
      "\n",
      "Dev accuracy:\n",
      "% of winners predicted correctly: 60.0%\n",
      "Average Rank-Biased Overlap: 0.562\n",
      "Mean Squared Error for Linear Regression: 4476.544595591514\n",
      "\n",
      "filling na values using method 5\n",
      "\n",
      "Train accuracy:\n",
      "% of winners predicted correctly: 63.83%\n",
      "Average Rank-Biased Overlap: 0.538\n",
      "Mean Squared Error for Linear Regression: 1030.1871555038801\n",
      "\n",
      "Dev accuracy:\n",
      "% of winners predicted correctly: 60.0%\n",
      "Average Rank-Biased Overlap: 0.562\n",
      "Mean Squared Error for Linear Regression: 4464.292050653677\n",
      "\n",
      "\n",
      "*****mip*****\n",
      "\n",
      "filling na values using method 4\n",
      "\n",
      "Train accuracy:\n",
      "% of winners predicted correctly: 28.0%\n",
      "Average Rank-Biased Overlap: 0.417\n",
      "Mean Squared Error for Linear Regression: 208.58511792790853\n",
      "\n",
      "Dev accuracy:\n",
      "% of winners predicted correctly: 0.0%\n",
      "Average Rank-Biased Overlap: 0.392\n",
      "Mean Squared Error for Linear Regression: 533.810351093619\n",
      "\n",
      "filling na values using method 2\n",
      "\n",
      "Train accuracy:\n",
      "% of winners predicted correctly: 28.0%\n",
      "Average Rank-Biased Overlap: 0.416\n",
      "Mean Squared Error for Linear Regression: 208.58510588546207\n",
      "\n",
      "Dev accuracy:\n",
      "% of winners predicted correctly: 0.0%\n",
      "Average Rank-Biased Overlap: 0.392\n",
      "Mean Squared Error for Linear Regression: 533.8111070547918\n",
      "\n",
      "filling na values using method 5\n",
      "\n",
      "Train accuracy:\n",
      "% of winners predicted correctly: 28.0%\n",
      "Average Rank-Biased Overlap: 0.418\n",
      "Mean Squared Error for Linear Regression: 208.59917282173424\n",
      "\n",
      "Dev accuracy:\n",
      "% of winners predicted correctly: 0.0%\n",
      "Average Rank-Biased Overlap: 0.384\n",
      "Mean Squared Error for Linear Regression: 533.8946490819793\n",
      "\n",
      "\n",
      "*****smoy*****\n",
      "\n",
      "filling na values using method 4\n",
      "\n",
      "Train accuracy:\n",
      "% of winners predicted correctly: 51.85%\n",
      "Average Rank-Biased Overlap: 0.458\n",
      "Mean Squared Error for Linear Regression: 372.3787418148702\n",
      "\n",
      "Dev accuracy:\n",
      "% of winners predicted correctly: 60.0%\n",
      "Average Rank-Biased Overlap: 0.552\n",
      "Mean Squared Error for Linear Regression: 1070.6729631340697\n",
      "\n",
      "filling na values using method 2\n",
      "\n",
      "Train accuracy:\n",
      "% of winners predicted correctly: 51.85%\n",
      "Average Rank-Biased Overlap: 0.458\n",
      "Mean Squared Error for Linear Regression: 372.37868068854\n",
      "\n",
      "Dev accuracy:\n",
      "% of winners predicted correctly: 60.0%\n",
      "Average Rank-Biased Overlap: 0.552\n",
      "Mean Squared Error for Linear Regression: 1070.6727699891849\n",
      "\n",
      "filling na values using method 5\n",
      "\n",
      "Train accuracy:\n",
      "% of winners predicted correctly: 51.85%\n",
      "Average Rank-Biased Overlap: 0.455\n",
      "Mean Squared Error for Linear Regression: 372.34742398764087\n",
      "\n",
      "Dev accuracy:\n",
      "% of winners predicted correctly: 60.0%\n",
      "Average Rank-Biased Overlap: 0.551\n",
      "Mean Squared Error for Linear Regression: 1070.6539209511527\n"
     ]
    }
   ],
   "source": [
    "for award in ['mvp', 'dpoy', 'roy', 'mip', 'smoy']:\n",
    "    print(f'\\n\\n*****{award}*****')\n",
    "    x_train_pnames, x_train, y_train, x_dev_pnames, x_dev, y_dev, x_test_pnames, x_test, y_test = get_data(award)\n",
    "    for fill_na_method in [4, 2, 5]:\n",
    "        print(f'\\nfilling na values using method {fill_na_method}')\n",
    "        x_train_filled, x_dev_filled, x_test_filled = fill_missing_stats(x_train, x_train_pnames, x_dev, x_dev_pnames,\n",
    "                                                                         x_test, x_test_pnames, method=fill_na_method)\n",
    "        reg = LinearRegression().fit(x_train_filled, y_train)\n",
    "        train_pred = reg.predict(x_train_filled)\n",
    "        dev_pred = reg.predict(x_dev_filled)\n",
    "        print('\\nTrain accuracy:')\n",
    "        print_accuracy(train_pred, y_train, x_train_pnames)\n",
    "        print('\\nDev accuracy:')\n",
    "        print_accuracy(dev_pred, y_dev, x_dev_pnames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Get Final Results</h2>\n",
    "After testing my model, I calculated its final accuracy on my test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "*****mvp*****\n",
      "\n",
      "filling na values using method 4\n",
      "\n",
      "Test accuracy:\n",
      "% of winners predicted correctly: 20.0%\n",
      "Average Rank-Biased Overlap: 0.726\n",
      "Mean Squared Error for Linear Regression: 2892.411088615582\n",
      "\n",
      "\n",
      "*****dpoy*****\n",
      "\n",
      "filling na values using method 4\n",
      "\n",
      "Test accuracy:\n",
      "% of winners predicted correctly: 20.0%\n",
      "Average Rank-Biased Overlap: 0.251\n",
      "Mean Squared Error for Linear Regression: 576.6248621263551\n",
      "\n",
      "\n",
      "*****roy*****\n",
      "\n",
      "filling na values using method 4\n",
      "\n",
      "Test accuracy:\n",
      "% of winners predicted correctly: 20.0%\n",
      "Average Rank-Biased Overlap: 0.63\n",
      "Mean Squared Error for Linear Regression: 2818.265612266596\n",
      "\n",
      "\n",
      "*****mip*****\n",
      "\n",
      "filling na values using method 4\n",
      "\n",
      "Test accuracy:\n",
      "% of winners predicted correctly: 0.0%\n",
      "Average Rank-Biased Overlap: 0.365\n",
      "Mean Squared Error for Linear Regression: 626.4988654704664\n",
      "\n",
      "\n",
      "*****smoy*****\n",
      "\n",
      "filling na values using method 4\n",
      "\n",
      "Test accuracy:\n",
      "% of winners predicted correctly: 40.0%\n",
      "Average Rank-Biased Overlap: 0.462\n",
      "Mean Squared Error for Linear Regression: 731.9334129988895\n"
     ]
    }
   ],
   "source": [
    "if GET_TEST_RESULTS:\n",
    "    for award in ['mvp', 'dpoy', 'roy', 'mip', 'smoy']:\n",
    "        print(f'\\n\\n*****{award}*****')\n",
    "        x_train_pnames, x_train, y_train, x_dev_pnames, x_dev, y_dev, x_test_pnames, x_test, y_test = get_data(award)\n",
    "        for fill_na_method in [4]:\n",
    "            print(f'\\nfilling na values using method {fill_na_method}')\n",
    "            x_train_filled, x_dev_filled, x_test_filled = fill_missing_stats(x_train, x_train_pnames, x_dev,\n",
    "                                                                             x_dev_pnames, x_test, x_test_pnames,\n",
    "                                                                             method=fill_na_method)\n",
    "            reg = LinearRegression().fit(x_train_filled, y_train)\n",
    "            test_pred = reg.predict(x_test_filled)\n",
    "            print('\\nTest accuracy:')\n",
    "            print_accuracy(test_pred, y_test, x_test_pnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
