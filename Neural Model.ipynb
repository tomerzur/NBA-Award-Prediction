{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Neural Model<h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.regularizers import l1, l2\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import rbo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, I will be using a multi-layer perceptron to make predictions for each award. This notebook includes the code I used to create this neural model and make predictions for each award.\n",
    "<br><br>\n",
    "This code should be run after you have finished running the 'preprocessing' notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Helper Functions</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I am loading helper functions that I wrote in order to load my data, scale the data, fill in missing/NA values, and calculate and print my accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "GET_TEST_RESULTS = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieves train, dev, and test data for the specified award\n",
    "def get_data(award_name):\n",
    "    x_train_pnames = pd.read_csv(f'data/train_x_{award}.csv', index_col=0)\n",
    "    y_train = pd.read_csv(f'data/train_y_{award}.csv', index_col=0)\n",
    "    x_dev_pnames = pd.read_csv(f'data/dev_x_{award}.csv', index_col=0)\n",
    "    y_dev = pd.read_csv(f'data/dev_y_{award}.csv', index_col=0)\n",
    "    x_test_pnames = pd.read_csv(f'data/test_x_{award}.csv', index_col=0)\n",
    "    y_test = pd.read_csv(f'data/test_y_{award}.csv', index_col=0)\n",
    "    x_train = x_train_pnames.drop(columns=['player', 'season'])\n",
    "    x_dev = x_dev_pnames.drop(columns=['player', 'season'])\n",
    "    x_test = x_test_pnames.drop(columns=['player', 'season'])\n",
    "    return x_train_pnames, x_train, y_train, x_dev_pnames, x_dev, y_dev, x_test_pnames, x_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some missing statistics in my dataset. These occur mostly for older players, as there are some statistics (such as steals and blocks) that weren't kept track of when the NBA first started. I will deal with these missing statistics in three ways:\n",
    "<br>\n",
    "Method 2 - Fill in zeros for all of the missing stats, and use all the data\n",
    "<br>\n",
    "Method 5 - Fill in mean values for all of missing stats, and use all of the data\n",
    "<br>\n",
    "Method 4 - Use linear regressions to predict each of the missing stats, and use all of the data\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "Some other ways I may implement in the future to explore dealing with missing statistics are:\n",
    "<br>\n",
    "Remove all of these rows (This should end up using all player seasons after 1979)\n",
    "<br>\n",
    "Drop all the columns with missing stats, and use all of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in the missing statistics (that were not kept track of for older players)\n",
    "# using one of the three methods mentioned above\n",
    "def fill_missing_stats(x_train, x_train_pnames, x_dev, x_dev_pnames, x_test, x_test_pnames, method=4):\n",
    "    if method == 2:\n",
    "        x_train_filled = x_train.fillna(0)\n",
    "        x_dev_filled = x_dev.fillna(0)\n",
    "        x_test_filled = x_test.fillna(0)\n",
    "    elif method == 4:\n",
    "        x_train_filled = copy.copy(x_train_pnames)\n",
    "        x_dev_filled = copy.copy(x_dev_pnames)\n",
    "        x_test_filled = copy.copy(x_test_pnames)\n",
    "        # three_p and three_pa - if season < 1980, set to NA\n",
    "        x_train_filled['three_p'] = np.where(x_train_filled.season < 1980, float('NaN'), x_train_filled.three_p)\n",
    "        x_train_filled['three_pa'] = np.where(x_train_filled.season < 1980, float('NaN'), x_train_filled.three_pa)\n",
    "        \n",
    "        x_train_filled = x_train_filled.drop(columns=['player', 'season'])\n",
    "        x_dev_filled = x_dev_filled.drop(columns=['player', 'season'])\n",
    "        x_test_filled = x_test_filled.drop(columns=['player', 'season'])\n",
    "\n",
    "        # predict all missing values for these stats using lin reg\n",
    "        # train data: player seasons where stat != NaN\n",
    "        # test data: player seasons where stat == NaN\n",
    "        for stat in ['three_p', 'three_pa', 'gs', 'orb', 'drb', 'stl', 'blk', 'tov']:\n",
    "            # check if this stat has missing values\n",
    "            if x_train_filled[stat].isnull().values.any():\n",
    "                train_stat = x_train_filled[x_train_filled[stat].notna()]\n",
    "                # for all lin reg predictions, don't use any of the columns that have missing values\n",
    "                x_train_stat = train_stat.drop(columns=['three_p', 'three_pa', 'gs', 'orb', 'drb', 'stl', 'blk', 'tov', 'three_pct', 'gs_pct'])\n",
    "                y_train_stat = train_stat[[stat]]\n",
    "                test_stat = x_train_filled[~x_train_filled[stat].notna()]\n",
    "                x_test_stat = test_stat.drop(columns=['three_p', 'three_pa', 'gs', 'orb', 'drb', 'stl', 'blk', 'tov', 'three_pct', 'gs_pct'])\n",
    "\n",
    "                reg_stat = LinearRegression().fit(x_train_stat, y_train_stat)\n",
    "                pred_test_stat = reg_stat.predict(x_test_stat)\n",
    "                pred_stat_dict = {index: round(value[0], 3) for index, value in zip(x_train_filled[~x_train_filled[stat].notna()].index, pred_test_stat)}\n",
    "                x_train_filled[stat] = x_train_filled[stat].fillna(pred_stat_dict)\n",
    "\n",
    "        # fill in three_pct - three_p / three_pa, gs_pct - gs / g\n",
    "        x_train_filled['three_pct'] = x_train_filled['three_p'] / x_train_filled['three_pa']\n",
    "        x_train_filled['gs_pct'] = x_train_filled['gs'] / x_train_filled['g']\n",
    "        x_train_filled = x_train_filled.fillna(0)\n",
    "        x_dev_filled['three_pct'] = x_dev_filled['three_p'] / x_dev_filled['three_pa']\n",
    "        x_dev_filled = x_dev_filled.fillna(0)\n",
    "        x_test_filled['three_pct'] = x_test_filled['three_p'] / x_test_filled['three_pa']\n",
    "        x_test_filled = x_test_filled.fillna(0)\n",
    "    elif method == 5:\n",
    "        x_train_filled = x_train.fillna(x_train.mean())\n",
    "        x_dev_filled = x_dev.fillna(x_dev.mean())\n",
    "        x_test_filled = x_test.fillna(x_test.mean())\n",
    "    else:\n",
    "        print('method of dealing with missing stats must be either 2, 4, or 5')\n",
    "    return x_train_filled, x_dev_filled, x_test_filled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The award points that players receive are very skewed, as most players received zero points for a given award. To reduce this skew, I scaled all of the award point values logarithmically.\n",
    "<br>\n",
    "<br>\n",
    "I also applied a Min Max scaler so that each feature would be in the range (0, 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log scale all the y values, then min-max scale all the x and y values\n",
    "def scale_vals(x_vals, y_vals):\n",
    "    # add 1 so that you can take log of players with 0 award points\n",
    "    y_log_vals = np.log(y_vals.award_pts_won + 1).values.reshape(-1, 1)\n",
    "    x_scaler = MinMaxScaler().fit(x_vals, y_vals)\n",
    "    x_vals = x_scaler.transform(x_vals)\n",
    "    y_scaler = MinMaxScaler()\n",
    "    y_vals = y_scaler.fit_transform(y_log_vals)\n",
    "    return x_vals, y_vals, y_scaler\n",
    "    \n",
    "def unscale_vals(y_vals_scaled, y_scaler):\n",
    "    y_log_vals = y_scaler.inverse_transform(y_vals_scaled)\n",
    "    y_vals = np.expm1(y_log_vals)\n",
    "    return y_vals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I decided to measure my models' performance using three metrics: Mean Squared Error, % of correct MVP predictions, and Rank-Biased Overlap.\n",
    "<br>\n",
    "I chose to use rank-biased overlap because it is an accuracy metric for rankings that weights higher ranked items more than lower ranked items. In addition, when comparing two lists using this metric, rank-biased overlap can deal with items that occur in one list but are not seen in the other list.\n",
    "<br>\n",
    "For more information on rank-biased overlap, see this article: http://codalism.com/research/papers/wmz10_tois.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print accuracy metrics by comparing the given lists (y_pred and y_actual)\n",
    "# accuracy metrics that I am using are % of correct winners picked, rank biased overlap, and mean squared error\n",
    "def print_accuracy(y_pred, y_actual, x_pnames, rbo_cutoff = None, verbose=0):\n",
    "    all_data = copy.copy(x_pnames)\n",
    "    all_data['award_pts_actual'] = y_actual['award_pts_won']\n",
    "    all_data['award_pts_pred'] = y_pred\n",
    "    num_correct = 0\n",
    "    num_yrs = 0\n",
    "    rbo_vals = []\n",
    "    for year in set(all_data.season):\n",
    "        # a. % of correct winners picked\n",
    "        data_in_yr = all_data[all_data['season'] == year]\n",
    "        pred_winner_row = data_in_yr['award_pts_pred'].argmax()\n",
    "        actual_winner_row = data_in_yr['award_pts_actual'].argmax()\n",
    "        pred_winner, pred_pts = data_in_yr.iloc[pred_winner_row]['player'], data_in_yr.iloc[pred_winner_row]['award_pts_pred']\n",
    "        actual_winner, actual_pts = data_in_yr.iloc[actual_winner_row]['player'], data_in_yr.iloc[actual_winner_row]['award_pts_actual']\n",
    "        if verbose > 0:\n",
    "            print(f'{year}')\n",
    "            print(f'Predicted Winner: {pred_winner} ({pred_pts} award pts)')\n",
    "            print(f'Actual Winner: {actual_winner} ({actual_pts} award pts)')\n",
    "        if pred_winner == actual_winner:\n",
    "            num_correct += 1\n",
    "        num_yrs += 1\n",
    "        \n",
    "        # b. Rank-Biased Overlap\n",
    "        # calculate RBO:\n",
    "        # get rows in given year with players that received votes - sorted by num votes\n",
    "        vote_getters_df = data_in_yr[data_in_yr['award_pts_actual'] > 0]\n",
    "        num_vote_getters = len(vote_getters_df)\n",
    "        vote_getters_df = vote_getters_df.sort_values(by=['award_pts_actual'], ascending=False)\n",
    "        # get top-(num_vote_getters) rows from predictions\n",
    "        pred_vote_getters_df = data_in_yr.sort_values(by=['award_pts_pred'], ascending=False)\n",
    "        if rbo_cutoff == None:\n",
    "            pred_vote_getters_df = pred_vote_getters_df[:num_vote_getters]\n",
    "        else:\n",
    "            cutoff = min(rbo_cutoff, num_vote_getters)\n",
    "            vote_getters_df = vote_getters_df[:cutoff]\n",
    "            pred_vote_getters_df = pred_vote_getters_df[:cutoff]\n",
    "        vote_getters = vote_getters_df['player'].values\n",
    "        pred_vote_getters = pred_vote_getters_df['player'].values\n",
    "        # deal with edge case where two vote getters have exact same name\n",
    "        vote_getters = list(set(vote_getters))\n",
    "        pred_vote_getters = list(set(pred_vote_getters))\n",
    "        #print(len(vote_getters))\n",
    "        #print(len(pred_vote_getters))\n",
    "        if verbose > 1:\n",
    "            print('Actual vote getters:')\n",
    "            print(vote_getters)\n",
    "            print(f'Predicted top-{num_vote_getters} vote getters:')\n",
    "            print(pred_vote_getters)\n",
    "        # compute RBO from these two lists\n",
    "        rbo_num = rbo.RankingSimilarity(vote_getters, pred_vote_getters).rbo()\n",
    "        rbo_vals.append(rbo_num)\n",
    "        if verbose > 0:\n",
    "            print(f'Rank Biased Overlap: {rbo_num}')\n",
    "        \n",
    "    print(f'% of winners predicted correctly: {round(num_correct / num_yrs * 100, 2)}%')\n",
    "    print(f'Average Rank-Biased Overlap: {round(sum(rbo_vals) / len(rbo_vals), 3)}')\n",
    "    # c. MSE\n",
    "    mse = mean_squared_error(y_actual, y_pred)\n",
    "    print(f'Mean Squared Error: {mse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Implementing Neural Model</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, I implement a separate neural model for predicting each of the five awards. I manually tested changing a bunch of different hyperparameters one at a time in order to come up with the best set of hyperparameters I could. One area for future improvement would be to use grid search or another method to search for better hyperparameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "*****mvp*****\n",
      "\n",
      "filling na values using method 4\n",
      "\n",
      "Train accuracy:\n",
      "% of winners predicted correctly: 40.0%\n",
      "Average Rank-Biased Overlap: 0.608\n",
      "Mean Squared Error: 3455.0053425848796\n",
      "\n",
      "Dev accuracy:\n",
      "% of winners predicted correctly: 20.0%\n",
      "Average Rank-Biased Overlap: 0.448\n",
      "Mean Squared Error: 5248.896052518296\n",
      "\n",
      "filling na values using method 2\n",
      "\n",
      "Train accuracy:\n",
      "% of winners predicted correctly: 38.18%\n",
      "Average Rank-Biased Overlap: 0.59\n",
      "Mean Squared Error: 3455.0033176317493\n",
      "\n",
      "Dev accuracy:\n",
      "% of winners predicted correctly: 20.0%\n",
      "Average Rank-Biased Overlap: 0.438\n",
      "Mean Squared Error: 5248.89100670029\n",
      "\n",
      "filling na values using method 5\n",
      "\n",
      "Train accuracy:\n",
      "% of winners predicted correctly: 38.18%\n",
      "Average Rank-Biased Overlap: 0.584\n",
      "Mean Squared Error: 3454.952450350006\n",
      "\n",
      "Dev accuracy:\n",
      "% of winners predicted correctly: 20.0%\n",
      "Average Rank-Biased Overlap: 0.439\n",
      "Mean Squared Error: 5248.842520457459\n",
      "\n",
      "\n",
      "*****dpoy*****\n",
      "\n",
      "filling na values using method 4\n",
      "\n",
      "Train accuracy:\n",
      "% of winners predicted correctly: 10.71%\n",
      "Average Rank-Biased Overlap: 0.308\n",
      "Mean Squared Error: 227.08927280303638\n",
      "\n",
      "Dev accuracy:\n",
      "% of winners predicted correctly: 20.0%\n",
      "Average Rank-Biased Overlap: 0.23\n",
      "Mean Squared Error: 582.2330934135449\n",
      "\n",
      "filling na values using method 2\n",
      "\n",
      "Train accuracy:\n",
      "% of winners predicted correctly: 14.29%\n",
      "Average Rank-Biased Overlap: 0.302\n",
      "Mean Squared Error: 227.0916748798138\n",
      "\n",
      "Dev accuracy:\n",
      "% of winners predicted correctly: 20.0%\n",
      "Average Rank-Biased Overlap: 0.221\n",
      "Mean Squared Error: 582.2394186062369\n",
      "\n",
      "filling na values using method 5\n",
      "\n",
      "Train accuracy:\n",
      "% of winners predicted correctly: 14.29%\n",
      "Average Rank-Biased Overlap: 0.298\n",
      "Mean Squared Error: 227.08884748022555\n",
      "\n",
      "Dev accuracy:\n",
      "% of winners predicted correctly: 20.0%\n",
      "Average Rank-Biased Overlap: 0.228\n",
      "Mean Squared Error: 582.2319740598647\n",
      "\n",
      "\n",
      "*****roy*****\n",
      "\n",
      "filling na values using method 4\n",
      "\n",
      "Train accuracy:\n",
      "% of winners predicted correctly: 53.19%\n",
      "Average Rank-Biased Overlap: 0.66\n",
      "Mean Squared Error: 1366.0977613702298\n",
      "\n",
      "Dev accuracy:\n",
      "% of winners predicted correctly: 80.0%\n",
      "Average Rank-Biased Overlap: 0.511\n",
      "Mean Squared Error: 6098.135192549801\n",
      "\n",
      "filling na values using method 2\n",
      "\n",
      "Train accuracy:\n",
      "% of winners predicted correctly: 55.32%\n",
      "Average Rank-Biased Overlap: 0.653\n",
      "Mean Squared Error: 1366.214568667455\n",
      "\n",
      "Dev accuracy:\n",
      "% of winners predicted correctly: 80.0%\n",
      "Average Rank-Biased Overlap: 0.555\n",
      "Mean Squared Error: 6098.545499102555\n",
      "\n",
      "filling na values using method 5\n",
      "\n",
      "Train accuracy:\n",
      "% of winners predicted correctly: 55.32%\n",
      "Average Rank-Biased Overlap: 0.662\n",
      "Mean Squared Error: 1366.2546153386809\n",
      "\n",
      "Dev accuracy:\n",
      "% of winners predicted correctly: 80.0%\n",
      "Average Rank-Biased Overlap: 0.555\n",
      "Mean Squared Error: 6098.6887173563755\n",
      "\n",
      "\n",
      "*****mip*****\n",
      "\n",
      "filling na values using method 4\n",
      "\n",
      "Train accuracy:\n",
      "% of winners predicted correctly: 0.0%\n",
      "Average Rank-Biased Overlap: 0.207\n",
      "Mean Squared Error: 222.23047162270657\n",
      "\n",
      "Dev accuracy:\n",
      "% of winners predicted correctly: 0.0%\n",
      "Average Rank-Biased Overlap: 0.29\n",
      "Mean Squared Error: 568.1234863951729\n",
      "\n",
      "filling na values using method 2\n",
      "\n",
      "Train accuracy:\n",
      "% of winners predicted correctly: 0.0%\n",
      "Average Rank-Biased Overlap: 0.235\n",
      "Mean Squared Error: 222.2224549828748\n",
      "\n",
      "Dev accuracy:\n",
      "% of winners predicted correctly: 0.0%\n",
      "Average Rank-Biased Overlap: 0.352\n",
      "Mean Squared Error: 568.1035358804248\n",
      "\n",
      "filling na values using method 5\n",
      "\n",
      "Train accuracy:\n",
      "% of winners predicted correctly: 0.0%\n",
      "Average Rank-Biased Overlap: 0.229\n",
      "Mean Squared Error: 222.21962040530929\n",
      "\n",
      "Dev accuracy:\n",
      "% of winners predicted correctly: 0.0%\n",
      "Average Rank-Biased Overlap: 0.343\n",
      "Mean Squared Error: 568.0965813814662\n",
      "\n",
      "\n",
      "*****smoy*****\n",
      "\n",
      "filling na values using method 4\n",
      "\n",
      "Train accuracy:\n",
      "% of winners predicted correctly: 33.33%\n",
      "Average Rank-Biased Overlap: 0.494\n",
      "Mean Squared Error: 436.618432056016\n",
      "\n",
      "Dev accuracy:\n",
      "% of winners predicted correctly: 60.0%\n",
      "Average Rank-Biased Overlap: 0.37\n",
      "Mean Squared Error: 1240.921690824693\n",
      "\n",
      "filling na values using method 2\n",
      "\n",
      "Train accuracy:\n",
      "% of winners predicted correctly: 37.04%\n",
      "Average Rank-Biased Overlap: 0.514\n",
      "Mean Squared Error: 436.61896126415667\n",
      "\n",
      "Dev accuracy:\n",
      "% of winners predicted correctly: 80.0%\n",
      "Average Rank-Biased Overlap: 0.343\n",
      "Mean Squared Error: 1240.9229953253944\n",
      "\n",
      "filling na values using method 5\n",
      "\n",
      "Train accuracy:\n",
      "% of winners predicted correctly: 37.04%\n",
      "Average Rank-Biased Overlap: 0.495\n",
      "Mean Squared Error: 436.61534384748603\n",
      "\n",
      "Dev accuracy:\n",
      "% of winners predicted correctly: 60.0%\n",
      "Average Rank-Biased Overlap: 0.356\n",
      "Mean Squared Error: 1240.9141818119017\n"
     ]
    }
   ],
   "source": [
    "for award in ['mvp', 'dpoy', 'roy', 'mip', 'smoy']:\n",
    "    print(f'\\n\\n*****{award}*****')\n",
    "    x_train_pnames, x_train, y_train, x_dev_pnames, x_dev, y_dev, x_test_pnames, x_test, y_test = get_data(award)\n",
    "    for fill_na_method in [4, 2, 5]:\n",
    "        print(f'\\nfilling na values using method {fill_na_method}')\n",
    "        x_train_filled, x_dev_filled, x_test_filled = fill_missing_stats(x_train, x_train_pnames, x_dev, x_dev_pnames,\n",
    "                                                                         x_test, x_test_pnames, method=fill_na_method)\n",
    "        x_train_scaled, y_train_scaled, y_train_scaler = scale_vals(x_train_filled, y_train)\n",
    "        x_dev_scaled, y_dev_scaled, y_dev_scaler = scale_vals(x_dev_filled, y_dev)\n",
    "        \n",
    "        # create model\n",
    "        model = Sequential()\n",
    "        #model.add(Dense(40, activation='relu', kernel_regularizer=l2(l=0.6)))\n",
    "        model.add(Dense(40, input_dim=x_train_filled.shape[1], activation='relu', kernel_regularizer=l2(l=0.6)))        \n",
    "        #model.add(Dense(40, activation='relu'))\n",
    "        #model.add(Dense(40, input_dim=x_train_filled.shape[1], activation='relu'))\n",
    "        #model.add(Dense(20, activation='relu', kernel_regularizer=l2(l=0.1)))\n",
    "        #model.add(Dense(1, activation='sigmoid', kernel_regularizer=l2(l=0.1)))\n",
    "        model.add(Dense(40, activation='relu'))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        #model.add(Dense(1))\n",
    "        #model.compile(loss='mse', optimizer=Adam(lr=0.01), metrics=['accuracy'])\n",
    "        model.compile(loss='mse', optimizer=SGD(lr=0.01, momentum=0.9, clipnorm=1.0), metrics=['accuracy'])\n",
    "        #model.compile(loss='mse', optimizer=SGD(lr=0.01, momentum=0.9), metrics=['accuracy'])\n",
    "        model.fit(x_train_scaled, y_train_scaled, epochs=50, batch_size=300, verbose=0)\n",
    "        \n",
    "        train_pred_scaled = model.predict(x_train_scaled)\n",
    "        dev_pred_scaled = model.predict(x_dev_scaled)\n",
    "        train_pred = unscale_vals(train_pred_scaled, y_train_scaler)\n",
    "        dev_pred = unscale_vals(dev_pred_scaled, y_dev_scaler)\n",
    "        print('\\nTrain accuracy:')\n",
    "        print_accuracy(train_pred, y_train, x_train_pnames)\n",
    "        print('\\nDev accuracy:')\n",
    "        print_accuracy(dev_pred, y_dev, x_dev_pnames, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Get Final Results</h2>\n",
    "After testing and tweaking my model, I calculated its final accuracy on my test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "*****mvp*****\n",
      "\n",
      "filling na values using method 4\n",
      "\n",
      "Test accuracy:\n",
      "% of winners predicted correctly: 20.0%\n",
      "Average Rank-Biased Overlap: 0.367\n",
      "Mean Squared Error: 3766.1329367187127\n",
      "\n",
      "\n",
      "*****dpoy*****\n",
      "\n",
      "filling na values using method 4\n",
      "\n",
      "Test accuracy:\n",
      "% of winners predicted correctly: 0.0%\n",
      "Average Rank-Biased Overlap: 0.291\n",
      "Mean Squared Error: 616.9849134132764\n",
      "\n",
      "\n",
      "*****roy*****\n",
      "\n",
      "filling na values using method 4\n",
      "\n",
      "Test accuracy:\n",
      "% of winners predicted correctly: 60.0%\n",
      "Average Rank-Biased Overlap: 0.755\n",
      "Mean Squared Error: 3684.5887546505296\n",
      "\n",
      "\n",
      "*****mip*****\n",
      "\n",
      "filling na values using method 4\n",
      "\n",
      "Test accuracy:\n",
      "% of winners predicted correctly: 0.0%\n",
      "Average Rank-Biased Overlap: 0.407\n",
      "Mean Squared Error: 660.1662631386804\n",
      "\n",
      "\n",
      "*****smoy*****\n",
      "\n",
      "filling na values using method 4\n",
      "\n",
      "Test accuracy:\n",
      "% of winners predicted correctly: 40.0%\n",
      "Average Rank-Biased Overlap: 0.518\n",
      "Mean Squared Error: 823.7149630759205\n"
     ]
    }
   ],
   "source": [
    "if GET_TEST_RESULTS:\n",
    "    for award in ['mvp', 'dpoy', 'roy', 'mip', 'smoy']:\n",
    "        print(f'\\n\\n*****{award}*****')\n",
    "        x_train_pnames, x_train, y_train, x_dev_pnames, x_dev, y_dev, x_test_pnames, x_test, y_test = get_data(award)\n",
    "        for fill_na_method in [4]:\n",
    "            print(f'\\nfilling na values using method {fill_na_method}')\n",
    "            x_train_filled, x_dev_filled, x_test_filled = fill_missing_stats(x_train, x_train_pnames, x_dev, x_dev_pnames,\n",
    "                                                                             x_test, x_test_pnames, method=fill_na_method)\n",
    "            x_train_scaled, y_train_scaled, y_train_scaler = scale_vals(x_train_filled, y_train)\n",
    "            x_dev_scaled, y_dev_scaled, y_dev_scaler = scale_vals(x_dev_filled, y_dev)\n",
    "            x_test_scaled, y_test_scaled, y_test_scaler = scale_vals(x_test_filled, y_test)\n",
    "\n",
    "            # create model\n",
    "            model = Sequential()\n",
    "            #model.add(Dense(40, activation='relu', kernel_regularizer=l2(l=0.6)))\n",
    "            model.add(Dense(40, input_dim=x_train_filled.shape[1], activation='relu', kernel_regularizer=l2(l=0.6)))        \n",
    "            #model.add(Dense(40, activation='relu'))\n",
    "            #model.add(Dense(40, input_dim=x_train_filled.shape[1], activation='relu'))\n",
    "            #model.add(Dense(20, activation='relu', kernel_regularizer=l2(l=0.1)))\n",
    "            #model.add(Dense(1, activation='sigmoid', kernel_regularizer=l2(l=0.1)))\n",
    "            model.add(Dense(40, activation='relu'))\n",
    "            model.add(Dense(1, activation='sigmoid'))\n",
    "            #model.add(Dense(1))\n",
    "            #model.compile(loss='mse', optimizer=Adam(lr=0.01), metrics=['accuracy'])\n",
    "            model.compile(loss='mse', optimizer=SGD(lr=0.01, momentum=0.9, clipnorm=1.0), metrics=['accuracy'])\n",
    "            #model.compile(loss='mse', optimizer=SGD(lr=0.01, momentum=0.9), metrics=['accuracy'])\n",
    "            model.fit(x_train_scaled, y_train_scaled, epochs=50, batch_size=300, verbose=0)\n",
    "\n",
    "            train_pred_scaled = model.predict(x_train_scaled)\n",
    "            test_pred_scaled = model.predict(x_test_scaled)\n",
    "            train_pred = unscale_vals(train_pred_scaled, y_train_scaler)\n",
    "            test_pred = unscale_vals(test_pred_scaled, y_test_scaler)\n",
    "            print('\\nTest accuracy:')\n",
    "            print_accuracy(test_pred, y_test, x_test_pnames, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
